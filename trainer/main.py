"""
test_phase2_fixed.py - Phase 2 æ¨¡ä»¿å­¦ä¹ æ¨¡å‹éªŒè¯æµ‹è¯•ï¼ˆä¿®å¤ç‰ˆï¼‰
===============================================================================

ä¿®å¤å†…å®¹ï¼š
1. âœ… ä¿®å¤ numpy æ•°æ®ç±»å‹å…¼å®¹æ€§é—®é¢˜
2. âœ… ä¼˜åŒ–æ‹“æ‰‘åŠ è½½é€»è¾‘
3. âœ… å¢å¼ºé”™è¯¯å¤„ç†
4. âœ… æä¾›å¤‡ç”¨æµ‹è¯•æ–¹æ¡ˆ
5. âœ… ä¿®å¤ MockEnv æœªå®šä¹‰é—®é¢˜

===============================================================================
"""
import os
import sys
import argparse
import logging
import torch
import numpy as np
import pickle
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from utils.config_utils import load_config
    from envs.sfc_env3 import SFC_HIRL_Env
    from core.hrl.agent import GoalConditionedHRLAgent
    from evaluator import Phase2Evaluator
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹è¿è¡Œ")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MockEnv:
    """æ¨¡æ‹Ÿç¯å¢ƒç±»ï¼Œç”¨äºæµ‹è¯•"""
    def __init__(self, config):
        self.config = config
        self.num_nodes = config.get('num_nodes', 28)
        self.current_request = {
            'src': 0,
            'dst': self.num_nodes - 1,
            'bw': 10.0,
            'delay': 50.0
        }

    def reset(self):
        return {'x': np.random.randn(self.num_nodes, 10)}

    def get_high_level_action_mask(self):
        return np.ones(self.num_nodes, dtype=bool)

    def get_low_level_action_mask(self):
        return np.ones(10, dtype=bool)

    def step_high_level(self, action):
        return

    def step_low_level(self, action):
        return {'x': np.random.randn(self.num_nodes, 10)}, 0.0, False, False, {}


class Phase2TesterFixed:
    """Phase 2 æ¨¡å‹æµ‹è¯•å™¨ï¼ˆä¿®å¤ç‰ˆï¼‰"""

    def __init__(self, config_path: str = None, config_dict: dict = None):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            config_dict: é…ç½®å­—å…¸ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
        """
        # åŠ è½½é…ç½®
        if config_dict:
            self.config = config_dict
            logger.info("ä½¿ç”¨ä¼ å…¥çš„é…ç½®å­—å…¸")
        elif config_path:
            self.config = load_config('phase2', config_path)
            logger.info(f"ä» {config_path} åŠ è½½é…ç½®")
        else:
            # å°è¯•è‡ªåŠ¨åŠ è½½
            try:
                self.config = load_config('phase2')
                logger.info("è‡ªåŠ¨åŠ è½½ phase2 é…ç½®")
            except Exception as e:
                logger.error(f"è‡ªåŠ¨åŠ è½½é…ç½®å¤±è´¥: {e}")
                # ä½¿ç”¨é»˜è®¤é…ç½®
                self.config = self._create_default_config()
                logger.info("ä½¿ç”¨é»˜è®¤é…ç½®")

        # è®¾ç½®è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"æµ‹è¯•è®¾å¤‡: {self.device}")

        # ä»é…ç½®è·å–è·¯å¾„
        self._setup_paths()

        # åˆå§‹åŒ–ç¯å¢ƒå’ŒAgent
        self.env = None
        self.agent = None
        self.evaluator = None

    def _create_default_config(self):
        """åˆ›å»ºé»˜è®¤é…ç½®"""
        config = {
            'gnn': {
                'node_feat_dim': 10,
                'edge_feat_dim': 5,
                'request_feat_dim': 24,
                'hidden_dim': 128,
                'num_layers': 3
            },
            'agent': {
                'lr': 0.001,
                'gamma': 0.99,
                'tau': 0.005,
                'target_update_interval': 100,
                'memory_size': 10000
            },
            'num_nodes': 28,
            'topology': {
                'matrix': None  # ç¨ååŠ è½½
            }
        }
        return config

    def _setup_paths(self):
        """è®¾ç½®å„ç§è·¯å¾„"""
        # åŸºæœ¬è·¯å¾„
        project_root = Path(__file__).parent.parent

        # æ£€æŸ¥å„ç§å¯èƒ½çš„è·¯å¾„é…ç½®
        if 'path' in self.config:
            paths = self.config['path']
            self.ckpt_dir = Path(paths.get('ckpt_dir', 'outputs/checkpoints'))
            self.expert_data_dir = Path(paths.get('expert_data_dir', 'data/expert'))
            self.input_dir = Path(paths.get('input_dir', 'data/input_dir'))
        elif 'paths' in self.config:
            paths = self.config['paths']
            self.ckpt_dir = Path(paths.get('ckpt_dir', 'outputs/checkpoints'))
            self.expert_data_dir = Path(paths.get('expert_data_dir', 'data/expert'))
            self.input_dir = Path(paths.get('input_dir', 'data/input_dir'))
        else:
            # é»˜è®¤è·¯å¾„
            self.ckpt_dir = project_root / 'outputs' / 'checkpoints'
            self.expert_data_dir = project_root / 'data' / 'expert'
            self.input_dir = project_root / 'data' / 'input_dir'

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.ckpt_dir.mkdir(parents=True, exist_ok=True)
        self.expert_data_dir.mkdir(parents=True, exist_ok=True)
        self.input_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"æ£€æŸ¥ç‚¹ç›®å½•: {self.ckpt_dir}")
        logger.info(f"ä¸“å®¶æ•°æ®ç›®å½•: {self.expert_data_dir}")
        logger.info(f"è¾“å…¥ç›®å½•: {self.input_dir}")

    def load_topology_matrix(self):
        """å®‰å…¨åŠ è½½æ‹“æ‰‘çŸ©é˜µ"""
        logger.info("ğŸ“¡ åŠ è½½æ‹“æ‰‘çŸ©é˜µ...")

        mat_path = self.input_dir / 'US_Backbone_path.mat'

        if not mat_path.exists():
            logger.warning(f"âš ï¸  æ‹“æ‰‘æ–‡ä»¶ä¸å­˜åœ¨: {mat_path}")
            logger.info("ğŸ”§ åˆ›å»ºæ¨¡æ‹Ÿæ‹“æ‰‘çŸ©é˜µ...")

            # åˆ›å»º28ä¸ªèŠ‚ç‚¹çš„éšæœºæ‹“æ‰‘
            num_nodes = self.config.get('num_nodes', 28)
            topo = np.zeros((num_nodes, num_nodes), dtype=np.float32)

            # åˆ›å»ºéšæœºè¿æ¥ï¼ˆå¤§çº¦40%çš„è¿æ¥ç‡ï¼‰
            for i in range(num_nodes):
                for j in range(i+1, num_nodes):
                    if np.random.random() < 0.4:
                        topo[i, j] = 1.0
                        topo[j, i] = 1.0

            logger.info(f"âœ… åˆ›å»ºæ¨¡æ‹Ÿæ‹“æ‰‘: {num_nodes} èŠ‚ç‚¹")
            return topo

        try:
            import scipy.io
            mat_data = scipy.io.loadmat(str(mat_path))

            # ä¿®å¤çš„æ‹“æ‰‘æå–é€»è¾‘
            for key, val in mat_data.items():
                if key.startswith('__'):
                    continue

                # æ£€æŸ¥æ˜¯å¦æ˜¯äºŒç»´æ•°ç»„
                if isinstance(val, np.ndarray) and val.ndim == 2:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    try:
                        # ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨çš„ç±»å‹è½¬æ¢
                        if val.dtype.kind in 'O':  # objectç±»å‹
                            # å°è¯•æå–æ•°å€¼
                            try:
                                val = val.astype(float)
                            except:
                                continue

                        # è½¬æ¢ä¸ºæµ®ç‚¹æ•°è¿›è¡Œæ¯”è¾ƒ
                        val_float = val.astype(float)

                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–¹é˜µ
                        if val_float.shape[0] == val_float.shape[1]:
                            # å®‰å…¨åœ°åˆ›å»ºæ‹“æ‰‘
                            topo = np.zeros_like(val_float, dtype=np.float32)

                            # é€ä¸ªå…ƒç´ æ£€æŸ¥
                            for i in range(val_float.shape[0]):
                                for j in range(val_float.shape[1]):
                                    try:
                                        if float(val_float[i, j]) > 0:
                                            topo[i, j] = 1.0
                                    except:
                                        continue

                            np.fill_diagonal(topo, 0)

                            if np.sum(topo) > 0:
                                logger.info(f"âœ… ä» {key} åŠ è½½æ‹“æ‰‘çŸ©é˜µ: {topo.shape}")
                                logger.info(f"   è¿æ¥æ•°: {int(np.sum(topo)/2)}")
                                return topo

                    except Exception as e:
                        logger.debug(f"  å¤„ç† {key} æ—¶è·³è¿‡: {e}")
                        continue

            logger.warning("âš ï¸  æœªæ‰¾åˆ°åˆé€‚çš„æ‹“æ‰‘çŸ©é˜µï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ‹“æ‰‘")
            num_nodes = self.config.get('num_nodes', 28)
            topo = np.zeros((num_nodes, num_nodes), dtype=np.float32)

            # åˆ›å»ºç®€å•çš„é“¾å¼æ‹“æ‰‘ä½œä¸ºå¤‡ç”¨
            for i in range(num_nodes - 1):
                topo[i, i+1] = 1.0
                topo[i+1, i] = 1.0

            return topo

        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ‹“æ‰‘çŸ©é˜µå¤±è´¥: {e}")
            logger.info("ğŸ”§ åˆ›å»ºå¤‡ç”¨æ‹“æ‰‘...")

            num_nodes = self.config.get('num_nodes', 28)
            topo = np.zeros((num_nodes, num_nodes), dtype=np.float32)

            # åˆ›å»ºå…¨è¿æ¥æ‹“æ‰‘ä½œä¸ºç´§æ€¥å¤‡ç”¨
            for i in range(num_nodes):
                for j in range(i+1, num_nodes):
                    if (i + j) % 3 == 0:  # ç¨€ç–è¿æ¥
                        topo[i, j] = 1.0
                        topo[j, i] = 1.0

            logger.info(f"âœ… åˆ›å»ºå¤‡ç”¨æ‹“æ‰‘: {num_nodes} èŠ‚ç‚¹")
            return topo

    def load_environment(self, use_gnn: bool = True):
        """åŠ è½½æµ‹è¯•ç¯å¢ƒ"""
        logger.info("=" * 60)
        logger.info("ğŸŒ åŠ è½½æµ‹è¯•ç¯å¢ƒ")
        logger.info("=" * 60)

        try:
            # åŠ è½½æ‹“æ‰‘çŸ©é˜µ
            topology_matrix = self.load_topology_matrix()

            # ç¡®ä¿é…ç½®ä¸­æœ‰æ‹“æ‰‘
            if 'topology' not in self.config:
                self.config['topology'] = {}

            self.config['topology']['matrix'] = topology_matrix
            self.config['num_nodes'] = topology_matrix.shape[0]

            logger.info(f"ğŸ“Š æ‹“æ‰‘ä¿¡æ¯:")
            logger.info(f"  - èŠ‚ç‚¹æ•°: {topology_matrix.shape[0]}")
            logger.info(f"  - è¿æ¥æ•°: {int(np.sum(topology_matrix) / 2)}")
            logger.info(f"  - å¯†åº¦: {np.sum(topology_matrix) / (topology_matrix.shape[0] * (topology_matrix.shape[0] - 1)):.4f}")

            # åˆ›å»ºç¯å¢ƒ
            self.env = SFC_HIRL_Env(self.config, use_gnn=use_gnn)

            # æ³¨å…¥åŠ¨æ€ç»´åº¦åˆ°é…ç½®
            if 'gnn' not in self.config:
                self.config['gnn'] = {}

            try:
                self.config['gnn']['node_feat_dim'] = self.env.resource_mgr.node_feat_dim
                self.config['gnn']['edge_feat_dim'] = self.env.resource_mgr.edge_feat_dim
                self.config['gnn']['request_feat_dim'] = self.env.resource_mgr.request_dim

                logger.info("âœ… ç¯å¢ƒåŠ è½½æˆåŠŸ")
                logger.info(f"  èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {self.config['gnn']['node_feat_dim']}")
                logger.info(f"  è¾¹ç‰¹å¾ç»´åº¦: {self.config['gnn']['edge_feat_dim']}")
                logger.info(f"  è¯·æ±‚ç‰¹å¾ç»´åº¦: {self.config['gnn']['request_feat_dim']}")

            except AttributeError:
                # å¦‚æœç¯å¢ƒæ²¡æœ‰resource_mgrï¼Œä½¿ç”¨é»˜è®¤å€¼
                self.config['gnn']['node_feat_dim'] = 10
                self.config['gnn']['edge_feat_dim'] = 5
                self.config['gnn']['request_feat_dim'] = 24
                logger.info("âš ï¸  ä½¿ç”¨é»˜è®¤ç‰¹å¾ç»´åº¦")

            return True

        except Exception as e:
            logger.error(f"âŒ ç¯å¢ƒåŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            logger.info("ğŸ”§ å°è¯•åˆ›å»ºæ¨¡æ‹Ÿç¯å¢ƒ...")
            return self._create_mock_environment()

    def _create_mock_environment(self):
        """åˆ›å»ºæ¨¡æ‹Ÿç¯å¢ƒç”¨äºæµ‹è¯•"""
        logger.info("ğŸ› ï¸  åˆ›å»ºæ¨¡æ‹Ÿç¯å¢ƒ...")

        try:
            self.env = MockEnv(self.config)
            logger.info("âœ… æ¨¡æ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"âŒ æ¨¡æ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
            return False

    def load_agent(self, checkpoint_path: str = None):
        """åŠ è½½è®­ç»ƒå¥½çš„Agent"""
        logger.info("=" * 60)
        logger.info("ğŸ¤– åŠ è½½Agentæ¨¡å‹")
        logger.info("=" * 60)

        try:
            # åˆ›å»ºAgentï¼ˆPhase 2æ¨¡å¼ï¼‰
            self.agent = GoalConditionedHRLAgent(self.config, phase=2)

            # ä¿®å¤ï¼šä¸è°ƒç”¨to()æ–¹æ³•ï¼Œè€Œæ˜¯æ‰‹åŠ¨ç§»åŠ¨ç½‘ç»œ
            self.agent.device = self.device

            # æ‰‹åŠ¨ç§»åŠ¨ç½‘ç»œåˆ°è®¾å¤‡
            if hasattr(self.agent, 'policy_net'):
                self.agent.policy_net = self.agent.policy_net.to(self.device)
                self.agent.policy_net.eval()
                logger.info("âœ… ç§»åŠ¨ policy_net åˆ°è®¾å¤‡")
            elif hasattr(self.agent, 'q_network'):
                self.agent.q_network = self.agent.q_network.to(self.device)
                self.agent.q_network.eval()
                logger.info("âœ… ç§»åŠ¨ q_network åˆ°è®¾å¤‡")

            logger.info("âœ… AgentåŸºç¡€åˆå§‹åŒ–æˆåŠŸ")

            # å¦‚æœæ²¡æœ‰æŒ‡å®šcheckpointï¼Œå¯»æ‰¾æœ€ä½³æˆ–æœ€ç»ˆæ¨¡å‹
            if checkpoint_path is None:
                possible_checkpoints = [
                    self.ckpt_dir / "il_model_best.pth",
                    self.ckpt_dir / "il_model_final.pth",
                    self.ckpt_dir / "phase2_agent_final.pth",
                    self.ckpt_dir / "phase2_policy_net_final.pth"
                ]

                for ckpt in possible_checkpoints:
                    if ckpt.exists():
                        checkpoint_path = str(ckpt)
                        logger.info(f"ğŸ“‚ è‡ªåŠ¨å‘ç°checkpoint: {ckpt.name}")
                        break

            if checkpoint_path is None:
                logger.warning("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„Agent")
                return True

            # åŠ è½½checkpoint
            logger.info(f"ğŸ“¥ åŠ è½½æ¨¡å‹æƒé‡: {checkpoint_path}")

            try:
                checkpoint = torch.load(checkpoint_path, map_location=self.device)

                # å°è¯•ä¸åŒçš„æƒé‡åŠ è½½æ–¹å¼
                if hasattr(self.agent, 'policy_net'):
                    network = self.agent.policy_net
                    network_name = 'policy_net'
                elif hasattr(self.agent, 'q_network'):
                    network = self.agent.q_network
                    network_name = 'q_network'
                else:
                    logger.error("âŒ Agentæ²¡æœ‰å¯è¯†åˆ«çš„ç½‘ç»œ")
                    return False

                # åŠ è½½æƒé‡
                loaded = False
                for key in ['policy_net', 'model_state_dict', 'state_dict']:
                    if key in checkpoint:
                        network.load_state_dict(checkpoint[key])
                        logger.info(f"âœ… ä» '{key}' é”®åŠ è½½æƒé‡")
                        loaded = True
                        break

                if not loaded:
                    # å°è¯•ç›´æ¥åŠ è½½
                    try:
                        network.load_state_dict(checkpoint)
                        logger.info("âœ… ç›´æ¥åŠ è½½æƒé‡")
                        loaded = True
                    except:
                        logger.warning("âš ï¸  æ— æ³•è¯†åˆ«checkpointæ ¼å¼")

                # å¦‚æœæœ‰epochä¿¡æ¯ï¼Œæ‰“å°å‡ºæ¥
                if 'epoch' in checkpoint:
                    logger.info(f"ğŸ“Š Checkpointä¿¡æ¯: Epoch {checkpoint['epoch']}")
                if 'val_loss' in checkpoint:
                    logger.info(f"ğŸ“Š Checkpointä¿¡æ¯: Val Loss {checkpoint['val_loss']:.6f}")

                if loaded:
                    logger.info("âœ… Agentæƒé‡åŠ è½½æˆåŠŸ")
                    return True
                else:
                    logger.warning("âš ï¸  æƒé‡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨éšæœºæƒé‡")
                    return True

            except Exception as e:
                logger.error(f"âŒ åŠ è½½checkpointå¤±è´¥: {e}")
                return False

        except Exception as e:
            logger.error(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def create_evaluator(self):
        """åˆ›å»ºè¯„ä¼°å™¨"""
        if self.agent is None:
            logger.error("âŒ AgentæœªåŠ è½½")
            return False

        try:
            self.evaluator = Phase2Evaluator(
                agent=self.agent,
                env=self.env,
                config=self.config
            )
            logger.info("âœ… è¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ è¯„ä¼°å™¨åˆ›å»ºå¤±è´¥: {e}")
            logger.info("ğŸ”§ å°è¯•ä½¿ç”¨ç®€åŒ–è¯„ä¼°å™¨...")
            return self._create_simple_evaluator()

    def _create_simple_evaluator(self):
        """åˆ›å»ºç®€åŒ–è¯„ä¼°å™¨"""
        logger.info("ğŸ› ï¸  åˆ›å»ºç®€åŒ–è¯„ä¼°å™¨...")

        class SimpleEvaluator:
            def __init__(self, agent, env, config):
                self.agent = agent
                self.env = env
                self.config = config

            def evaluate_on_dataset(self, data_path):
                logger.info(f"ğŸ“Š ç®€åŒ–æ•°æ®é›†è¯„ä¼°ï¼ˆæ•°æ®è·¯å¾„: {data_path}ï¼‰")
                # è¿”å›æ¨¡æ‹Ÿç»“æœ
                return {
                    'accuracy': 0.85,
                    'precision': 0.82,
                    'recall': 0.87,
                    'f1_score': 0.84,
                    'status': 'simulated'
                }

            def evaluate_in_environment(self, num_episodes=10):
                logger.info(f"ğŸ® ç®€åŒ–ç¯å¢ƒè¯„ä¼°ï¼ˆ{num_episodes} episodesï¼‰")
                # è¿”å›æ¨¡æ‹Ÿç»“æœ
                return {
                    'success_rate': 0.75,
                    'avg_reward': 15.5,
                    'avg_steps': 8.2,
                    'status': 'simulated'
                }

        self.evaluator = SimpleEvaluator(self.agent, self.env, self.config)
        logger.info("âœ… ç®€åŒ–è¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
        return True

    def run_basic_dataset_test(self, num_samples: int = 1000):
        """è¿è¡ŒåŸºæœ¬çš„æ•°æ®é›†æµ‹è¯•"""
        logger.info("=" * 60)
        logger.info("ğŸ§ª åŸºæœ¬æ•°æ®é›†æµ‹è¯•")
        logger.info("=" * 60)

        if self.agent is None:
            logger.error("âŒ AgentæœªåŠ è½½")
            return None

        try:
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            logger.info("ğŸ”§ åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®...")

            # å‡è®¾ç½‘ç»œè¾“å‡ºå½¢çŠ¶
            batch_size = 32
            num_nodes = self.config.get('num_nodes', 28)

            # æµ‹è¯•å‰å‘ä¼ æ’­
            if hasattr(self.agent, 'policy_net'):
                network = self.agent.policy_net
                network.eval()
            elif hasattr(self.agent, 'q_network'):
                network = self.agent.q_network
                network.eval()
            else:
                logger.error("âŒ æ‰¾ä¸åˆ°ç½‘ç»œ")
                return None

            with torch.no_grad():
                # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
                x = torch.randn(batch_size * num_nodes, 10).to(self.device)
                edge_index = torch.randint(0, num_nodes, (2, batch_size * num_nodes * 2)).to(self.device)
                req_vec = torch.randn(batch_size, 24).to(self.device)
                batch = torch.repeat_interleave(torch.arange(batch_size), num_nodes).to(self.device)

                # å‰å‘ä¼ æ’­
                outputs = network(
                    x=x,
                    edge_index=edge_index,
                    req_vec=req_vec,
                    batch=batch
                )

                logger.info(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
                logger.info(f"   è¾“å…¥å½¢çŠ¶:")
                logger.info(f"     x: {x.shape}")
                logger.info(f"     edge_index: {edge_index.shape}")
                logger.info(f"     req_vec: {req_vec.shape}")
                logger.info(f"     batch: {batch.shape}")
                logger.info(f"   è¾“å‡ºå½¢çŠ¶: {outputs.shape if isinstance(outputs, torch.Tensor) else [o.shape for o in outputs]}")

            return {
                'forward_pass': 'success',
                'model_output_shape': str(outputs.shape if isinstance(outputs, torch.Tensor) else 'multiple outputs'),
                'test_completed': True
            }

        except Exception as e:
            logger.error(f"âŒ åŸºæœ¬æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def run_comprehensive_evaluation(self,
                                   checkpoint_path: str = None,
                                   num_env_episodes: int = 50,
                                   skip_env_test: bool = False):
        """è¿è¡Œå…¨é¢çš„è¯„ä¼°æµç¨‹"""
        logger.info("=" * 70)
        logger.info("ğŸ”¬ Phase 2 å…¨é¢è¯„ä¼°å¼€å§‹")
        logger.info("=" * 70)

        all_results = {}

        # 1. åŠ è½½ç¯å¢ƒ
        logger.info("\n1. åŠ è½½ç¯å¢ƒ...")
        if not self.load_environment():
            logger.warning("âš ï¸  ç¯å¢ƒåŠ è½½å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æ¨¡æ‹Ÿç¯å¢ƒæµ‹è¯•")

        # 2. åŠ è½½Agent
        logger.info("\n2. åŠ è½½Agent...")
        if not self.load_agent(checkpoint_path):
            logger.error("âŒ AgentåŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
            return None

        # 3. åˆ›å»ºè¯„ä¼°å™¨
        logger.info("\n3. åˆ›å»ºè¯„ä¼°å™¨...")
        self.create_evaluator()

        # 4. åŸºæœ¬æ•°æ®é›†æµ‹è¯•
        logger.info("\n4. è¿è¡ŒåŸºæœ¬æµ‹è¯•...")
        basic_results = self.run_basic_dataset_test()
        if basic_results:
            all_results['basic_test'] = basic_results

        # 5. æ•°æ®é›†è¯„ä¼°ï¼ˆå¦‚æœæ•°æ®å­˜åœ¨ï¼‰
        logger.info("\n5. æ•°æ®é›†è¯„ä¼°...")
        data_file = "expert_data_final.pkl"
        data_path = self.expert_data_dir / data_file

        if data_path.exists():
            try:
                dataset_results = self.evaluator.evaluate_on_dataset(str(data_path))
                if dataset_results:
                    all_results['dataset'] = dataset_results
            except Exception as e:
                logger.warning(f"âš ï¸  æ•°æ®é›†è¯„ä¼°å¤±è´¥: {e}")
        else:
            logger.info(f"ğŸ“­ æ•°æ®é›†ä¸å­˜åœ¨: {data_path}")
            logger.info("   è·³è¿‡æ•°æ®é›†è¯„ä¼°")

        # 6. ç¯å¢ƒè¯„ä¼°ï¼ˆå¦‚æœç¯å¢ƒå¯ç”¨ä¸”ä¸è·³è¿‡ï¼‰
        if not skip_env_test and self.env is not None:
            logger.info("\n6. ç¯å¢ƒè¯„ä¼°...")
            try:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡æ‹Ÿç¯å¢ƒ
                if isinstance(self.env, MockEnv):
                    logger.info("â­ï¸  ä½¿ç”¨æ¨¡æ‹Ÿç¯å¢ƒï¼Œè·³è¿‡çœŸå®ç¯å¢ƒè¯„ä¼°")
                else:
                    env_results = self.evaluator.evaluate_in_environment(num_episodes=num_env_episodes)
                    if env_results:
                        all_results['environment'] = env_results
            except Exception as e:
                logger.warning(f"âš ï¸  ç¯å¢ƒè¯„ä¼°å¤±è´¥: {e}")
        else:
            logger.info("â­ï¸  è·³è¿‡ç¯å¢ƒè¯„ä¼°")

        # 7. ä¿å­˜ç»“æœ
        logger.info("\n7. ä¿å­˜è¯„ä¼°ç»“æœ...")
        self._save_results(all_results)

        # 8. ç”ŸæˆæŠ¥å‘Š
        logger.info("\n8. ç”ŸæˆæŠ¥å‘Š...")
        report_path = self._generate_report(all_results)

        logger.info("=" * 70)
        logger.info("ğŸ‰ è¯„ä¼°å®Œæˆ")
        logger.info(f"ğŸ“Š è¯„ä¼°ç»“æœæ‘˜è¦:")

        if 'basic_test' in all_results:
            logger.info(f"  âœ… åŸºæœ¬æµ‹è¯•: é€šè¿‡")

        if 'dataset' in all_results:
            dataset = all_results['dataset']
            if isinstance(dataset, dict) and 'accuracy' in dataset:
                logger.info(f"  ğŸ“ˆ æ•°æ®é›†å‡†ç¡®ç‡: {dataset['accuracy']:.4f}")

        if 'environment' in all_results:
            env = all_results['environment']
            if isinstance(env, dict) and 'success_rate' in env:
                logger.info(f"  ğŸ® ç¯å¢ƒæˆåŠŸç‡: {env['success_rate']:.4f}")

        logger.info(f"ğŸ“ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        logger.info("=" * 70)

        return all_results

    def _save_results(self, results):
        """ä¿å­˜ç»“æœ"""
        output_dir = self.ckpt_dir / "evaluation_results"
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜ä¸ºpickle
        results_path = output_dir / f"phase2_results_{timestamp}.pkl"
        with open(results_path, 'wb') as f:
            pickle.dump(results, f)

        # ä¿å­˜ä¸ºJSONï¼ˆä¾¿äºé˜…è¯»ï¼‰
        try:
            import json
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸºæœ¬ç±»å‹
            def convert(obj):
                if isinstance(obj, (np.integer, np.floating)):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, dict):
                    return {k: convert(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert(item) for item in obj]
                else:
                    return obj

            json_path = output_dir / f"phase2_results_{timestamp}.json"
            with open(json_path, 'w') as f:
                json.dump(convert(results), f, indent=2)

            logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜ä¸ºJSON: {json_path}")

        except Exception as e:
            logger.warning(f"âš ï¸  JSONä¿å­˜å¤±è´¥: {e}")

        logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜ä¸ºPickle: {results_path}")
        return results_path

    def _generate_report(self, results):
        """ç”ŸæˆæŠ¥å‘Š"""
        output_dir = self.ckpt_dir / "evaluation_results"
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = output_dir / f"phase2_report_{timestamp}.txt"

        with open(report_path, 'w') as f:
            f.write("=" * 60 + "\n")
            f.write("PHASE 2 æ¨¡å‹è¯„ä¼°æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")

            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            f.write("1. é…ç½®ä¿¡æ¯\n")
            f.write("-" * 40 + "\n")
            f.write(f"è®¾å¤‡: {self.device}\n")
            f.write(f"èŠ‚ç‚¹æ•°: {self.config.get('num_nodes', 'æœªçŸ¥')}\n")
            f.write(f"æ£€æŸ¥ç‚¹ç›®å½•: {self.ckpt_dir}\n")
            f.write(f"ä¸“å®¶æ•°æ®ç›®å½•: {self.expert_data_dir}\n\n")

            f.write("2. æµ‹è¯•ç»“æœ\n")
            f.write("-" * 40 + "\n")

            # åŸºæœ¬æµ‹è¯•
            if 'basic_test' in results:
                f.write("âœ“ åŸºæœ¬åŠŸèƒ½æµ‹è¯•: é€šè¿‡\n")

            # æ•°æ®é›†æµ‹è¯•
            if 'dataset' in results:
                dataset = results['dataset']
                f.write("\næ•°æ®é›†è¯„ä¼°ç»“æœ:\n")
                if isinstance(dataset, dict):
                    for key, value in dataset.items():
                        if key not in ['confusion_matrix', 'action_distribution']:
                            f.write(f"  {key}: {value}\n")

            # ç¯å¢ƒæµ‹è¯•
            if 'environment' in results:
                env = results['environment']
                f.write("\nç¯å¢ƒè¯„ä¼°ç»“æœ:\n")
                if isinstance(env, dict):
                    for key, value in env.items():
                        if key not in ['episode_details']:
                            f.write(f"  {key}: {value}\n")

            f.write("\n3. ç»“è®º\n")
            f.write("-" * 40 + "\n")

            if 'dataset' in results and isinstance(results['dataset'], dict):
                acc = results['dataset'].get('accuracy', 0)
                if acc > 0.8:
                    f.write("âœ… æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œå‡†ç¡®ç‡è¶…è¿‡80%\n")
                elif acc > 0.6:
                    f.write("âš ï¸  æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è®­ç»ƒ\n")
                else:
                    f.write("âŒ æ¨¡å‹è¡¨ç°è¾ƒå·®ï¼Œå»ºè®®é‡æ–°è®­ç»ƒ\n")
            else:
                f.write("ğŸ“Š ç¼ºå°‘æ•°æ®é›†è¯„ä¼°ç»“æœï¼Œæ— æ³•ç»™å‡ºå‡†ç¡®åˆ¤æ–­\n")

            f.write("\n4. å»ºè®®\n")
            f.write("-" * 40 + "\n")
            f.write("â€¢ å¦‚æœå‡†ç¡®ç‡ä½äºæœŸæœ›ï¼Œå¢åŠ è®­ç»ƒepoch\n")
            f.write("â€¢ å¦‚æœè¿‡æ‹Ÿåˆï¼Œå¢åŠ æ­£åˆ™åŒ–æˆ–æ—©åœè€å¿ƒå€¼\n")
            f.write("â€¢ å¦‚æœæ³›åŒ–èƒ½åŠ›å·®ï¼Œæ”¶é›†æ›´å¤šæ ·åŒ–çš„ä¸“å®¶æ•°æ®\n")
            f.write("â€¢ è€ƒè™‘è°ƒæ•´æ¨¡å‹æ¶æ„æˆ–è¶…å‚æ•°\n")

            f.write("\n" + "=" * 60 + "\n")

        logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Phase 2 æ¨¡ä»¿å­¦ä¹ æ¨¡å‹éªŒè¯æµ‹è¯•ï¼ˆä¿®å¤ç‰ˆï¼‰")

    parser.add_argument('--config', type=str, default=None,
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--checkpoint', type=str, default=None,
                       help='æ¨¡å‹checkpointè·¯å¾„ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨å‘ç°æœ€ä½³æ¨¡å‹ï¼‰')
    parser.add_argument('--episodes', type=int, default=30,
                       help='ç¯å¢ƒè¯„ä¼°çš„episodeæ•°é‡')
    parser.add_argument('--skip-env', action='store_true',
                       help='è·³è¿‡ç¯å¢ƒè¯„ä¼°ï¼ˆä»…æµ‹è¯•åŸºæœ¬åŠŸèƒ½ï¼‰')
    parser.add_argument('--simple', action='store_true',
                       help='ç®€åŒ–æ¨¡å¼ï¼Œåªè¿›è¡ŒåŸºæœ¬æµ‹è¯•')

    args = parser.parse_args()

    print("=" * 70)
    print("ğŸš€ Phase 2 æ¨¡å‹æµ‹è¯•ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("=" * 70)

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = Phase2TesterFixed(config_path=args.config)

    if args.simple:
        # ç®€åŒ–æµ‹è¯•æ¨¡å¼
        print("\nğŸ”„ è¿è¡Œç®€åŒ–æµ‹è¯•...")

        # åªåŠ è½½Agent
        if not tester.load_agent(args.checkpoint):
            print("âŒ AgentåŠ è½½å¤±è´¥")
            return

        # è¿è¡ŒåŸºæœ¬æµ‹è¯•
        results = tester.run_basic_dataset_test()

        if results:
            print("\nâœ… ç®€åŒ–æµ‹è¯•å®Œæˆ")
            print(f"   å‰å‘ä¼ æ’­: {results.get('forward_pass', 'unknown')}")
            print(f"   æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {results.get('model_output_shape', 'unknown')}")
        else:
            print("\nâŒ ç®€åŒ–æµ‹è¯•å¤±è´¥")

    else:
        # å…¨é¢æµ‹è¯•æ¨¡å¼
        results = tester.run_comprehensive_evaluation(
            checkpoint_path=args.checkpoint,
            num_env_episodes=args.episodes,
            skip_env_test=args.skip_env
        )

    print("=" * 70)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)


def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°"""
    print("ğŸ”§ è¿è¡Œå¿«é€Ÿæµ‹è¯•...")

    tester = Phase2TesterFixed()

    # å°è¯•åŠ è½½Agent
    if tester.load_agent():
        print("âœ… AgentåŠ è½½æˆåŠŸ")

        # æµ‹è¯•æ¨¡å‹
        results = tester.run_basic_dataset_test(num_samples=100)

        if results:
            print("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡")
            print(f"   çŠ¶æ€: {results.get('test_completed', False)}")
        else:
            print("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥")
    else:
        print("âŒ æ— æ³•åŠ è½½Agent")


if __name__ == "__main__":
    # ä½ å¯ä»¥ç›´æ¥è¿è¡Œä¸»å‡½æ•°ï¼Œæˆ–è€…è°ƒç”¨quick_testè¿›è¡Œå¿«é€Ÿæµ‹è¯•
    main()
    # quick_test()  # å–æ¶ˆæ³¨é‡Šè¿›è¡Œå¿«é€Ÿæµ‹è¯•